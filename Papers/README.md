# Reading list

## Introduction

- [ ] Linguistic unit discovery from multi-modal inputs in unwritten languages: Summary of the "Speaking Rosetta" JSALT 2017 Workshop. [[paper](https://arxiv.org/pdf/1802.05092.pdf)].[[note](https://github.com/YimingXu1/multimodel-learning-notes/blob/main/Papers/Linguistic%20Unit%20Discovery.md)].

## ASR 

- [ ] Breaking the unwritten kanguage barrier: The Bulb project.[[Paper](https://www.sciencedirect.com/science/article/pii/S1877050916300370)].

## Speech&Image

- [ ] Align or attend? Toward More Efficient and Accurate Spoken Word Discovery Using Speech-to-Image Retrieval.[[paper](http://homepage.tudelft.nl/f7h35/papers/icassp21.3.pdf)].
- [ ] Learning to Recognise Words using Visually Grounded Speech. [[paper](http://homepage.tudelft.nl/f7h35/papers/iscas2021.1.pdf)].
- [ ] Image2speech: Automatically generating audio descriptions of images. [[paper](http://odettescharenborg.ruhosting.nl/wp-content/uploads/2015/02/hasegawajohnson_isga18.pdf)].

## Text&Image

- [x] Modeling Text with Graph Convolutional Network for Cross-Modal Information Retrieval. [[paper](https://arxiv.org/pdf/1802.00985.pdf)].[[note](https://github.com/YimingXu1/multimodel-learning-notes/blob/main/Papers/Linguistic%20Unit%20Discovery.md)].

- [ ] Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval. [[paper](https://arxiv.org/pdf/1910.05134.pdf)].[[note](https://github.com/YimingXu1/multimodel-learning-notes/blob/main/Papers/Linguistic%20Unit%20Discovery.md)].
